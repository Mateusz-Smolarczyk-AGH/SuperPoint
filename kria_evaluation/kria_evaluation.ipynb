{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635f5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/pynq-venv/lib/python3.8/site-packages/pynq/pl_server/xrt_device.py:59: UserWarning: xbutil failed to run - unable to determine XRT version\n",
      "  warnings.warn(\"xbutil failed to run - unable to determine XRT version\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import platform\n",
    "import tqdm\n",
    "from typing import Tuple, List, Union, Any\n",
    "import pynq_dpu\n",
    "import pynq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8d747",
   "metadata": {},
   "source": [
    "### Jest to ostatnia część, w której przetestujemy nasz nauczony model po kwantyzacji na docelowej platformie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c47e3c51",
   "metadata": {},
   "source": [
    "Definiujemy na początku klasę `TimeMeasurement`. Jest to dokładnie ta sama klasa, którą wykorzystywaliśmy w dwóch poprzednich etapach. Pozwoli ona nam na sprawdzenie czasu przetwarzania danych.\n",
    "\n",
    "Dodatkowo, tworzymy klasę `EvalLoader`. Pozwoli nam ona na odczytanie danych zapisanych w formacie `.npz`, które przygotowaliśmy w poprzedniej części. Standardowo, ustalony jest rozmiar batcha na 1, a nazwa pliku to `eval_MNIST.npz`. Dostosuj jedynie nazwę, jeżeli się nie zgadza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d15c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalLoader:\n",
    "    def __init__(self, \n",
    "                 batch_size: int = 1, \n",
    "                 npz_path: str = 'eval_MNIST.npz') -> None:\n",
    "        data = np.load(npz_path)\n",
    "        self.data = data['data'].astype(np.float32)\n",
    "        self.targets = data['targets']\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i >= len(self):\n",
    "            raise StopIteration\n",
    "\n",
    "        beg = min(i * self.batch_size, self.data.shape[0])\n",
    "        end = min(beg + self.batch_size, self.data.shape[0])\n",
    "\n",
    "        return self.data[beg:end, ...], self.targets[beg:end]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] // self.batch_size\n",
    "\n",
    "\n",
    "class TimeMeasurement:\n",
    "    def __init__(self, context_name: str, frames: int) -> None:\n",
    "        self.context_name: str = context_name\n",
    "        self.frames: int = frames\n",
    "        self.begin: float = None\n",
    "        self.end: float = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.begin = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "\n",
    "    @property\n",
    "    def time(self) -> float:\n",
    "        if self.begin is None or self.end is None:\n",
    "            raise RuntimeError()\n",
    "        return int(self.end - self.begin)\n",
    "\n",
    "    @property\n",
    "    def fps(self):\n",
    "        return self.frames / self.time\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = int(t - h*60 - min*60)\n",
    "        ms = int((t - np.floor(t))*1000)\n",
    "\n",
    "        return f\"Execution time: {h}:{min}:{s}:{ms}, processed {self.frames} frames, throughput: {self.fps} fps.\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        t = self.time\n",
    "        h = t // 60\n",
    "        min = (t - h*60) // 60\n",
    "        s = np.floor(t - h*60 - min*60)\n",
    "        ms = np.floor((t - np.floor(t))*1000)\n",
    "\n",
    "        return f'TimeMeasurement(context=\"{self.context_name}\",\"{h}:{min}:{s}:{ms}\", frames={self.frames}, throughput={self.fps})'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6363babd",
   "metadata": {},
   "source": [
    "Definiujemy metrykę `Accuracy`. Jest ona taka sama jak w poprzednich częściach, ale możesz zdefiniować ją sam. \n",
    "\n",
    "Z wartości `y_pred` wyznacz wartości maksymalne funkcją `np.argmax`. Zrób to względem `axis=1`. Następnie porównaj uzyskany wektor z `y_ref`. Wynik porównania wpisz do zmiennej `cmp`. Na koniec wyznacz wartość `score`, która jest równa zsumowanej wartości wektora `cmp` (.sum()) podzielona przez długość wektora `cmp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae866502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyMetric:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, y_pred: np.ndarray, y_ref: np.ndarray) -> float:\n",
    "        y_pred = ... #TODO\n",
    "        cmp = ... #TODO\n",
    "        score  = ... #TODO\n",
    "\n",
    "        return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb8cd9e7",
   "metadata": {},
   "source": [
    "Tworzymy klasę `CrossEntropyLoss`. Nie jest ona wymagana i może ona standardowo zwracać wartość 0. Jeżeli jednak ktoś byłby zainteresowany `dodatkowym zadaniem`, można ją zaimplementować na podstawie dokumentacji PyTorch lub internetu :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb0a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, \n",
    "                 y_pred: np.ndarray, \n",
    "                 y_ref: np.ndarray\n",
    "                 ) -> Any:\n",
    "        \n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592772ad",
   "metadata": {},
   "source": [
    "Inicjalizujemy generator danych, metrykę, funkcję straty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ac42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ... #TODO\n",
    "metric = ... #TODO\n",
    "criterion = ... #TODO\n",
    "tm = TimeMeasurement(\"Evaluation on KV260\", loader.batch_size * len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfafb34",
   "metadata": {},
   "source": [
    "Zdefiniuj funkcję `softmax`. Zobacz jak ona działa w dokumentacji PyTorch lub w internecie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2229e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray, axis=1):\n",
    "    #TODO\n",
    "    return ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcb90dce",
   "metadata": {},
   "source": [
    "Tworzymy klasę NetworkDPU. Podczas inicjalizacji przyjmuje skompilowany model `MiniResNet_qu.xmodel` oraz ścieżkę do pliku `dpu.bit`. Pozostałe pliki `dpu` muszą znajdować się w tym samym folderze i muszą się tak samo nazywać!\n",
    "\n",
    "Funkcja `input_float_to_int8` konwertuje dane z przestrzeni `float` do `int8`.\n",
    "\n",
    "Funkcja `output_int8_to_float` wykonuje odwrotną operację.\n",
    "\n",
    "Funkcja `process` wykonuje przetwarzanie danych. Zaimplementuj ją, wykonując kolejne operacje:\n",
    "1. Przekonwertuj daną wejściową `x` z przestrzeni `float` do przestrzeni `int`,\n",
    "2. Wpisz przekonwertowaną daną do zerowego indeksu bufowa wejściowego `buff_in`,\n",
    "3. Wywołaj funkcję `self.dpu.execute_async`, gdzie jako pierwszy parametr podajesz bufor wejściowy, a jako drugi parametr bufor wyjściowy. Funkcja zwróci indeks - zapisz go do zmiennej `job_id`,\n",
    "4. Poczekaj aż wątek obliczenia się wykona - wykorzystaj funkcję `self.dpu.wait`, gdzie parametrem jest indeks `job_id`.\n",
    "5. Odczytaj pierwszą wartość z bufora `buff_out`. Przypisz ją do zmiennej `y`,\n",
    "6. Przekonwertuj zmienną `y` do typu `float`,\n",
    "7. Wykonaj funkcję `softmax` na zmiennej `y` i ją zwróć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364364fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDPU:\n",
    "    \n",
    "    def __init__(self, xmodel_path: str = 'MiniResNet_qu.xmodel', dpu_path: str = 'dpu.bit'):\n",
    "        self.ov: pynq_dpu.DpuOverlay = pynq_dpu.DpuOverlay(dpu_path, download=True)\n",
    "        self.ov.load_model(xmodel_path)\n",
    "        self.dpu = self.ov.runner\n",
    "        print(self.ov.runner)\n",
    "        inputTensors = self.dpu.get_input_tensors()\n",
    "        outputTensors = self.dpu.get_output_tensors()\n",
    "        # get list of shapes\n",
    "        shapeIn = np.array([it.dims for it in inputTensors])\n",
    "        shapeOut = np.array([ot.dims for ot in outputTensors])\n",
    "        self.shapeIn = shapeIn\n",
    "        self.shapeOut = shapeOut\n",
    "        self.buff_in = [np.zeros(sh, np.int8, order='C') for sh in shapeIn]\n",
    "        self.buff_out = [np.zeros(sh, np.int8, order='C') for sh in shapeOut]\n",
    "        \n",
    "        self.input_repr = [(it.get_attr('bit_width'), it.get_attr('fix_point')) for it in inputTensors]\n",
    "        self.output_repr = [(ot.get_attr('bit_width'), ot.get_attr('fix_point')) for ot in outputTensors]\n",
    "    \n",
    "    def input_float_to_int8(self, x: np.ndarray) -> np.ndarray:\n",
    "        BIT_WIDTH, PRECISION_BITS = self.input_repr[0]\n",
    "        x = x * (2**PRECISION_BITS)\n",
    "        x = np.floor(x)\n",
    "        x = np.clip(x,-128, 127)\n",
    "        return x.astype(np.int8)\n",
    "    \n",
    "    def output_int8_to_float(self, y: np.ndarray):\n",
    "        BIT_WIDTH, PRECISION_BITS = self.output_repr[0]\n",
    "        PRECISION = 1 / 2**PRECISION_BITS\n",
    "        y = y * PRECISION\n",
    "        return y.astype(np.float32)\n",
    "    \n",
    "    def process(self, x: np.ndarray):\n",
    "        x = ...#TODO\n",
    "        self.buff_in[0] = ...#TODO\n",
    "        # start DPU thread\n",
    "        job_id = ...#TODO\n",
    "        self.dpu.wait(...)\n",
    "        y = ... #TODO\n",
    "        y = ... #TODO\n",
    "        y = ... #TODO\n",
    "        return y\n",
    "    \n",
    "    def __call__(self, x: np.ndarray) -> Any:\n",
    "        return self.process(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f150c17",
   "metadata": {},
   "source": [
    "Zainicjalizuj model sieci DPU, podając ścieżki do modelu i pliku `dpu.bit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3fb127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vart::Runner@0x39a31f50\n"
     ]
    }
   ],
   "source": [
    "net = NetworkDPU(xmodel_path='MiniResNet_qu.xmodel', \n",
    "                 dpu_path='dpu.bit')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fb98438",
   "metadata": {},
   "source": [
    "Tworzymy funkcję do ewaluacji modelu. Jeżeli ktoś zaimplementować Cross Entropy, to wartość loss będzie uwzględniania. W innym przypadku będzie zwracać 0 i nie będziemy na to zwracać uwagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61b7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: NetworkDPU,\n",
    "               data_loader: EvalLoader,\n",
    "               criterion: CrossEntropyLoss,\n",
    "               metric: AccuracyMetric,\n",
    "               ) -> Tuple[float, float]:\n",
    "\n",
    "    print(f\"Running on platform: {platform.platform()}, \"\n",
    "          f\"machine: {platform.machine()}, \"\n",
    "          f\"python_version: {platform.python_version()}, \"\n",
    "          f\"processor: {platform.processor()}, \"\n",
    "          f\"system: {platform.system()}, \"\n",
    "          )\n",
    "    total_loss: float = 0.0\n",
    "    total_accuracy: float = 0.0\n",
    "    samples_num: int = 0\n",
    "    \n",
    "    for i, (X, y_ref) in tqdm.tqdm(enumerate(data_loader),):\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(y_pred, y_ref)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        accuracy = metric(y_pred, y_ref)\n",
    "\n",
    "        total_loss += loss * y_pred.shape[0]\n",
    "        total_accuracy += accuracy * y_pred.shape[0]\n",
    "        samples_num += y_pred.shape[0]\n",
    "\n",
    "    if samples_num == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    return total_loss / samples_num, total_accuracy / samples_num\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85113b4c",
   "metadata": {},
   "source": [
    "Uruchamiamy ewaluację. Porównaj wyniki uzyskane podczas ewaluacji modelu zmiennoprzecinkowego.\n",
    "\n",
    "Oczekiwany jest przyrost ilości przetwarzanych danych na sekundę, przy minimalnej lub żadnej utracie dokładności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5236e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on platform: Linux-5.4.0-1021-xilinx-zynqmp-aarch64-with-glibc2.29, machine: aarch64, python_version: 3.8.10, processor: aarch64, system: Linux, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:07, 1412.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0:0:7:0, processed 10000 frames, throughput: 1428.5714285714287 fps.\n",
      "Loss:  0.0\n",
      "Accuracy:  0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tm:\n",
    "    loss, acc = evaluation(net, loader, criterion, metric)\n",
    "    \n",
    "print(str(tm))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53c6ce",
   "metadata": {},
   "source": [
    "## Udało Ci się wykonać wszystkie zadania! Gratulacje :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
